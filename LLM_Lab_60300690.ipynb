{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJSd_92jUpg3"
      },
      "source": [
        "# Lab Activity: Working with Mistrtal\n",
        "## Noor Elburdini (60300690)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B6jek4vfUism",
        "outputId": "6d38128e-61a1-4de9-fcbf-863075badbb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.12.2-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpx>=0.28.1 (from mistralai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 (from mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from mistralai)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai) (2.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai) (2.9.0.post0)\n",
            "Collecting pyyaml<7.0.0,>=6.0.2 (from mistralai)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai) (0.4.1)\n",
            "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai) (4.2.0)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai) (1.0.2)\n",
            "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->mistralai) (7.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->mistralai) (4.14.0)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: requests~=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (2.32.3)\n",
            "Collecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
            "  Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<2.0.0,>=1.33.1->mistralai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->mistralai) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->mistralai) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.0)\n",
            "Downloading mistralai-1.12.2-py3-none-any.whl (500 kB)\n",
            "Downloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
            "Installing collected packages: pyyaml, protobuf, invoke, eval-type-backport, opentelemetry-proto, opentelemetry-api, httpx, googleapis-common-protos, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, mistralai\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "Successfully installed eval-type-backport-0.3.1 googleapis-common-protos-1.72.0 httpx-0.28.1 invoke-2.2.1 mistralai-1.12.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-http-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 protobuf-6.33.5 pyyaml-6.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install mistralai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oWB8KGdlUtxb",
        "outputId": "80a00a0c-675b-41fa-ed6f-839fd6869fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: mistralai in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.12.2)\n",
            "Requirement already satisfied: streamlit in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.50.0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.21.0)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from flask->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from flask->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask->-r requirements.txt (line 1)) (1.6.2)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (0.3.1)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (1.39.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (2.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from mistralai->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (5.0.1)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (5.3.3)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: packaging<26,>=20 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (6.33.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (4.14.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (3.1.43)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r requirements.txt (line 3)) (6.4.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (4.23.0)\n",
            "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 3)) (4.0.7)\n",
            "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.1.2->flask->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->mistralai->-r requirements.txt (line 2)) (7.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai->-r requirements.txt (line 2)) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai->-r requirements.txt (line 2)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai->-r requirements.txt (line 2)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->mistralai->-r requirements.txt (line 2)) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 3)) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai->-r requirements.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->mistralai->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->mistralai->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 3)) (0.10.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->mistralai->-r requirements.txt (line 2)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72dcJXqpZL4A"
      },
      "source": [
        "Load API key and helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG9tTcO5RkNz",
        "outputId": "b69c1f07-0ee2-46e8-9118-858e8b66ae47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MISTRAL_API_KEY: fr006GjkNB8tbu5PQ7ODgvT9JFYg7hYn\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"MISTRAL_API_KEY\"] = \"fr006GjkNB8tbu5PQ7ODgvT9JFYg7hYn\"\n",
        "print(f\"MISTRAL_API_KEY: {os.environ.get('MISTRAL_API_KEY')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MeQr3YUdRqGB"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv(\"MISTRAL_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ewVTUbwkRtE4"
      },
      "outputs": [],
      "source": [
        "from mistralai import Mistral, UserMessage\n",
        "\n",
        "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
        "    model = \"mistral-large-latest\"\n",
        "    client = Mistral(api_key=api_key)\n",
        "\n",
        "    messages = [UserMessage(content=user_message)]\n",
        "\n",
        "    chat_response = client.chat.complete(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "    return chat_response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "VjogwYnWRwYZ",
        "outputId": "4ff9f2c3-be8e-423f-dc82-605b3ae20e08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! Iâ€™m an AI assistant here to help with a wide range of tasks. Hereâ€™s what I can do for you:\\n\\n### **General Assistance**\\n- Answer questions (facts, explanations, advice).\\n- Summarize articles, books, or documents.\\n- Help with brainstorming ideas (writing, projects, business, etc.).\\n- Provide step-by-step guides (recipes, DIY, tech setup, etc.).\\n\\n### **Writing & Editing**\\n- Write or edit emails, essays, reports, or creative stories.\\n- Generate blog posts, social media captions, or marketing copy.\\n- Improve grammar, clarity, and style in your writing.\\n- Translate text between languages (though not perfectly).\\n\\n### **Learning & Research**\\n- Explain complex topics (science, history, philosophy, etc.).\\n- Help with homework or study guides (math, coding, languages, etc.).\\n- Find and summarize research papers or news articles.\\n- Recommend books, courses, or learning resources.\\n\\n### **Productivity & Organization**\\n- Create to-do lists, schedules, or planners.\\n- Help with goal-setting and habit tracking.\\n- Draft professional documents (resumes, cover letters, proposals).\\n- Generate templates (meeting agendas, contracts, etc.).\\n\\n### **Coding & Tech Help**\\n- Write, debug, or explain code (Python, JavaScript, SQL, etc.).\\n- Suggest tools or frameworks for projects.\\n- Help with API integrations or automation scripts.\\n- Explain tech concepts (AI, blockchain, cybersecurity, etc.).\\n\\n### **Creative Tasks**\\n- Generate poems, song lyrics, or short stories.\\n- Help design characters, worlds, or plots for games/stories.\\n- Suggest names (businesses, pets, fictional characters, etc.).\\n- Create jokes, riddles, or fun trivia.\\n\\n### **Lifestyle & Wellness**\\n- Suggest meal plans, workout routines, or meditation tips.\\n- Help with travel planning (itineraries, packing lists, etc.).\\n- Provide mental health resources or coping strategies.\\n- Recommend movies, music, or books based on your tastes.\\n\\n### **Business & Finance**\\n- Draft business plans or pitch decks.\\n- Explain financial concepts (investing, taxes, budgeting).\\n- Generate marketing strategies or ad copy.\\n- Help with customer service responses or FAQs.\\n\\n### **Fun & Entertainment**\\n- Play text-based games (trivia, riddles, choose-your-own-adventure).\\n- Generate memes, puns, or funny captions.\\n- Roleplay scenarios (e.g., historical figures, fictional characters).\\n- Recommend games, shows, or hobbies.\\n\\n### **Limitations**\\n- I donâ€™t have real-time internet access (my knowledge cutoff is **October 2023**).\\n- I canâ€™t browse websites, use apps, or access personal data.\\n- Iâ€™m not a substitute for professional advice (medical, legal, financial).\\n- My responses are generated based on patterns, not personal experience.\\n\\n**What would you like help with today?** ðŸ˜Š'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral(\"hello, what can you do?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhe3wSEya9Gy"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1snamfW7SAhN"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "You are a bank customer service bot.\n",
        "Your task is to assess customer intent and categorize customer\n",
        "inquiry after <<<>>> into one of the following predefined categories:\n",
        "\n",
        "card arrival\n",
        "change pin\n",
        "exchange rate\n",
        "country support\n",
        "cancel transfer\n",
        "charge dispute\n",
        "\n",
        "If the text doesn't fit into any of the above categories,\n",
        "classify it as:\n",
        "\n",
        "customer service\n",
        "\n",
        "You will only respond with the predefined category.\n",
        "Do not provide explanations or notes.\n",
        "\n",
        "###\n",
        "Here are some examples:\n",
        "\n",
        "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card.\n",
        "Category: card arrival\n",
        "\n",
        "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees.\n",
        "Category: exchange rate\n",
        "\n",
        "Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time.\n",
        "Category: country support\n",
        "\n",
        "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer.\n",
        "Category: customer service\n",
        "\n",
        "###\n",
        "<<<\n",
        "Inquiry: {inquiry}\n",
        ">>>\n",
        "Category:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUXLC6qbCOv"
      },
      "source": [
        "### Ask Mistral to check the spelling and grammar of your prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dO9P6zTmS8zl"
      },
      "outputs": [],
      "source": [
        "response = mistral(f\"Please correct the spelling and grammar of \\\n",
        "this prompt and return a text that is the same prompt,\\\n",
        "with the spelling and grammar fixed: {prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIl1J5R0S_Oy",
        "outputId": "c0e61127-0971-46b8-dd40-adaa9527c65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hereâ€™s your corrected prompt with proper spelling and grammar:\n",
            "\n",
            "---\n",
            "\n",
            "You are a bank customer service bot.\n",
            "Your task is to assess customer intent and categorize the customer inquiry within the `<<<>>>` markers into one of the following predefined categories:\n",
            "\n",
            "- card arrival\n",
            "- change pin\n",
            "- exchange rate\n",
            "- country support\n",
            "- cancel transfer\n",
            "- charge dispute\n",
            "\n",
            "If the text does not fit into any of the above categories, classify it as:\n",
            "\n",
            "- customer service\n",
            "\n",
            "You will respond **only** with the predefined category.\n",
            "Do not provide explanations or notes.\n",
            "\n",
            "###\n",
            "Here are some examples:\n",
            "\n",
            "**Inquiry:** How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card.\n",
            "**Category:** card arrival\n",
            "\n",
            "**Inquiry:** I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees.\n",
            "**Category:** exchange rate\n",
            "\n",
            "**Inquiry:** What countries are supported? I will be traveling and living abroad for an extended period of time.\n",
            "**Category:** country support\n",
            "\n",
            "**Inquiry:** Can I get help starting my computer? I am having difficulty starting my computer.\n",
            "**Category:** customer service\n",
            "\n",
            "###\n",
            "<<<\n",
            "**Inquiry:** {inquiry}\n",
            ">>>\n",
            "**Category:**\n",
            "\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtrZeDZXbLwj"
      },
      "source": [
        "Try out the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uoIZQdPATBN_",
        "outputId": "0a7e2487-1894-47d9-a2d4-62fa04898028"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'country support'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral(\n",
        "    prompt.format(\n",
        "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bNFfy7sbQyw"
      },
      "source": [
        "## Information Extraction with JSON Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z4WnjnfRTLGe"
      },
      "outputs": [],
      "source": [
        "medical_notes = \"\"\"\n",
        "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
        "of increased thirst, frequent urination, fatigue, and unexplained\n",
        "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
        "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
        "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
        "with meals. It was noted during the consultation that the patient is\n",
        "a current smoker.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D8S2E_AeTT6t"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Extract information from the following medical notes:\n",
        "{medical_notes}\n",
        "\n",
        "Return json format with the following JSON schema:\n",
        "{{\n",
        "  \"age\": {{\n",
        "    \"type\": \"integer\"\n",
        "  }},\n",
        "  \"gender\": {{\n",
        "    \"type\": \"string\",\n",
        "    \"enum\": [\"male\", \"female\", \"other\"]\n",
        "  }},\n",
        "  \"diagnosis\": {{\n",
        "    \"type\": \"string\",\n",
        "    \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
        "  }},\n",
        "  \"weight\": {{\n",
        "    \"type\": \"integer\"\n",
        "  }},\n",
        "  \"smoking\": {{\n",
        "    \"type\": \"string\",\n",
        "    \"enum\": [\"yes\", \"no\"]\n",
        "  }}\n",
        "}}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEraJrkFTi_4",
        "outputId": "6b980205-5196-41d4-c772-3eaf9def0862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"age\": 60,\n",
            "  \"gender\": \"male\",\n",
            "  \"diagnosis\": \"diabetes\",\n",
            "  \"weight\": 210,\n",
            "  \"smoking\": \"yes\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt, is_json=True)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btcSEZglbX8z"
      },
      "source": [
        "## Personalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s3UfHC2pTpf9"
      },
      "outputs": [],
      "source": [
        "email = \"\"\"\n",
        "\n",
        "Dear mortgage lender,\n",
        "\n",
        "What's your 30-year fixed-rate APR, how is it compared to the 15-year\n",
        "fixed rate?\n",
        "\n",
        "Regards,\n",
        "Anna\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qRNPEnCWTxwW"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a mortgage lender customer service bot, and your task is to\n",
        "create personalized email responses to address customer questions.\n",
        "Answer the customer's inquiry using the provided facts below. Ensure\n",
        "that your response is clear, concise, and directly addresses the\n",
        "customer's question. Address the customer in a friendly and\n",
        "professional manner. Sign the email with\n",
        "\"Lender Customer Support.\"\n",
        "# Facts\n",
        "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
        "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
        "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
        "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
        "7-year ARM: interest rate 7.011%, APR 7.660%\n",
        "5-year ARM: interest rate 6.880%, APR 7.754%\n",
        "3-year ARM: interest rate 6.125%, APR 7.204%\n",
        "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
        "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
        "# Email\n",
        "{email} \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbHON4qaT6c9",
        "outputId": "7b621407-7d89-4c60-d0a6-fc2c746b5ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Subject:** Your 30-Year and 15-Year Fixed-Rate APR Details\n",
            "\n",
            "Dear Anna,\n",
            "\n",
            "Thank you for reaching out! Here are the details you requested:\n",
            "\n",
            "- **30-year fixed-rate:** The APR is **6.484%**.\n",
            "- **15-year fixed-rate:** The APR is **5.848%**.\n",
            "\n",
            "The 15-year fixed-rate offers a lower APR compared to the 30-year option, which typically means lower overall interest costs over the life of the loan. However, the shorter term also comes with higher monthly payments.\n",
            "\n",
            "Would you like help comparing these options further or exploring other loan types? Let me know how I can assist!\n",
            "\n",
            "Best regards,\n",
            "**Lender Customer Support**\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt, is_json=True)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZprIAAObdsU"
      },
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JlNlfcdNUAIN"
      },
      "outputs": [],
      "source": [
        "newsletter = \"\"\"\n",
        "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft.\n",
        "\n",
        "Whatâ€™s new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year).\n",
        "\n",
        "Model specs: The new modelsâ€™ parameter counts, architectures, and training methods are undisclosed.\n",
        "\n",
        "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropicâ€™s Claude 2, Googleâ€™s Gemini Pro, and Metaâ€™s Llama 2 70B.\n",
        "\n",
        "Both models are fluent in French, German, Spanish, and Italian. Theyâ€™re trained for function calling and JSON-format output.\n",
        "\n",
        "Microsoftâ€™s investment in Mistral AI is significant but tiny compared to its investments in other AI companies.\n",
        "\n",
        "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
        "\n",
        "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta.\n",
        "\n",
        "Yes, but: Mistral AIâ€™s partnership with Microsoft has divided European lawmakers and regulators.\n",
        "\n",
        "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers.\n",
        "Weâ€™re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with Microsoft could significantly accelerate its ability to compete with larger AI players, though it may also intensify regulatory and competitive tensions within the European AI ecosystem.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqN0YWuUVAU0",
        "outputId": "63569435-2a7c-4b43-bb77-60d878e0f934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Subject:** Your 30-Year and 15-Year Fixed-Rate APR Details\n",
            "\n",
            "Dear Anna,\n",
            "\n",
            "Thank you for reaching out! Here are the details you requested:\n",
            "\n",
            "- **30-year fixed-rate:** The APR is **6.484%**.\n",
            "- **15-year fixed-rate:** The APR is **5.848%**.\n",
            "\n",
            "The 15-year fixed-rate offers a lower APR compared to the 30-year option, which typically means lower overall interest costs over the life of the loan. However, the shorter term also comes with higher monthly payments.\n",
            "\n",
            "Would you like help comparing these options further or exploring other loan types? Let me know how I can assist!\n",
            "\n",
            "Best regards,\n",
            "**Lender Customer Support**\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "naViZ9EyWVuQ"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a commentator. Your task is to write a report on a newsletter.\n",
        "When presented with the newsletter, come up with interesting questions to ask,\n",
        "and answer each question.\n",
        "Afterward, combine all the information and write a report in the markdown\n",
        "format.\n",
        "# Newsletter:\n",
        "{newsletter}\n",
        "# Instructions:\n",
        "## Summarize:\n",
        "In clear and concise language, summarize the key points and themes\n",
        "presented in the newsletter.\n",
        "## Interesting Questions:\n",
        "Generate three distinct and thought-provoking questions that can be\n",
        "asked about the content of the newsletter. For each question:\n",
        "-\n",
        "After\n",
        "\"Q:\n",
        "\"\n",
        ", describe the problem\n",
        "-\n",
        "After\n",
        "\"A:\n",
        "\"\n",
        ", provide a detailed explanation of the problem addressed\n",
        "in the question.\n",
        "-\n",
        "Enclose the ultimate answer in <>.\n",
        "## Write a analysis report\n",
        "Using the summary and the answers to the interesting questions,\n",
        "create a comprehensive report in Markdown format.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-updev4uWcWz",
        "outputId": "eef07ae7-f225-4119-ae36-b32b6b95c7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# **Analysis Report: Mistral AIâ€™s New Models and Microsoft Partnership**\n",
            "\n",
            "## **Summary**\n",
            "Mistral AI, a European AI startup founded in 2023 by former Google and Meta engineers, has unveiled two new closed large language models (LLMs): **Mistral Large** and **Mistral Small**, joining the previously released **Mistral Medium**. Key highlights include:\n",
            "- **Performance**: Mistral Large outperforms competitors like Claude 2, Gemini Pro, and Llama 2 70B on the MMLU benchmark (81.2%).\n",
            "- **Multilingual & Functional Capabilities**: Fluent in French, German, Spanish, and Italian, with support for function calling and JSON output.\n",
            "- **Microsoft Partnership**: A strategic alliance to train custom models for European governments, despite Microsoftâ€™s relatively small investment compared to its other AI ventures.\n",
            "- **Regulatory & Competitive Tensions**: The partnership has sparked debate among European lawmakers and regulators, raising concerns about market dominance and data sovereignty.\n",
            "\n",
            "The collaboration provides Mistral AI with critical computational resources and market access, accelerating its growth in the competitive AI landscape.\n",
            "\n",
            "---\n",
            "\n",
            "## **Interesting Questions**\n",
            "\n",
            "### **Q1: How does Mistral AIâ€™s performance on the MMLU benchmark compare to other leading models, and what does this imply about its capabilities?**\n",
            "**Problem:**\n",
            "The MMLU (Massive Multitask Language Understanding) benchmark is a key metric for evaluating an LLMâ€™s general knowledge and reasoning abilities. Mistral Largeâ€™s score of **81.2%** suggests strong performance, but how does this compare to other models, and what does it reveal about its real-world applicability?\n",
            "\n",
            "**A:**\n",
            "- **Benchmark Comparison**:\n",
            "  - Mistral Large (81.2%) outperforms:\n",
            "    - Anthropicâ€™s Claude 2 (~78.5%)\n",
            "    - Googleâ€™s Gemini Pro (~79.1%)\n",
            "    - Metaâ€™s Llama 2 70B (~68.9%)\n",
            "  - It remains slightly behind **GPT-4 (86.4%)** and **Gemini Ultra (90%)**, but the gap is narrowing.\n",
            "- **Implications**:\n",
            "  - **General Knowledge & Reasoning**: A high MMLU score indicates strong performance in academic and professional tasks, making Mistral Large competitive for enterprise and government use.\n",
            "  - **Efficiency vs. Scale**: Mistral AI achieves this with undisclosed parameter counts, suggesting optimized training methods rather than brute-force scaling.\n",
            "  - **Multilingual Edge**: Its fluency in European languages gives it an advantage in regional markets where competitors may lag.\n",
            "\n",
            "**<Ultimate Answer: Mistral Largeâ€™s MMLU performance places it among the top-tier LLMs, demonstrating strong reasoning and multilingual capabilities, though it still trails GPT-4 and Gemini Ultra. This suggests a lean, efficient model that could disrupt the AI market without requiring massive computational resources.>**\n",
            "\n",
            "---\n",
            "\n",
            "### **Q2: Why has Mistral AIâ€™s partnership with Microsoft divided European lawmakers and regulators?**\n",
            "**Problem:**\n",
            "Microsoftâ€™s investment in Mistral AI is relatively small, yet the partnership has sparked controversy. What are the underlying concerns, and how might this impact Europeâ€™s AI strategy?\n",
            "\n",
            "**A:**\n",
            "- **Regulatory Concerns**:\n",
            "  - **Market Dominance**: Microsoft already has significant influence in AI (e.g., OpenAI, Azure cloud). Critics fear this partnership could further consolidate power in the hands of a few tech giants, stifling European startups.\n",
            "  - **Data Sovereignty**: European governments may be wary of sensitive data being processed on Microsoftâ€™s infrastructure, raising compliance issues with GDPR and other regulations.\n",
            "  - **Strategic Autonomy**: The EU has pushed for \"digital sovereignty,\" promoting homegrown AI solutions. A partnership with a U.S. tech giant could undermine this goal.\n",
            "- **Competitive Tensions**:\n",
            "  - **Startup vs. Incumbent**: Mistral AI is a European champion, but aligning with Microsoft may alienate policymakers who prefer local alternatives (e.g., Aleph Alpha, Hugging Face).\n",
            "  - **Subsidies & Funding**: If Mistral AI relies on Microsoftâ€™s cloud resources, it could face scrutiny over whether it is truly independent or just a \"European front\" for U.S. tech.\n",
            "\n",
            "**<Ultimate Answer: The partnership raises concerns about market concentration, data privacy, and Europeâ€™s ability to maintain AI independence. While it provides Mistral AI with critical resources, it may conflict with the EUâ€™s broader goals of fostering a sovereign AI ecosystem.>**\n",
            "\n",
            "---\n",
            "\n",
            "### **Q3: What are the potential long-term implications of Mistral AIâ€™s collaboration with Microsoft for the global AI market?**\n",
            "**Problem:**\n",
            "Mistral AIâ€™s rapid rise and Microsoftâ€™s backing could reshape the AI landscape. How might this partnership influence competition, innovation, and geopolitical dynamics in AI?\n",
            "\n",
            "**A:**\n",
            "- **Competitive Dynamics**:\n",
            "  - **Challenging U.S. Dominance**: Mistral AI could become a viable alternative to U.S.-based models (OpenAI, Google, Anthropic), especially in Europe.\n",
            "  - **Pressure on Big Tech**: If Mistral AI continues to deliver high-performance models with fewer resources, it may force larger players to innovate faster or risk losing market share.\n",
            "- **Geopolitical & Regulatory Impact**:\n",
            "  - **EU AI Act Compliance**: Mistral AIâ€™s models may be better aligned with EU regulations, giving it an edge in government contracts.\n",
            "  - **U.S.-EU Tech Rivalry**: The partnership could be seen as a strategic move to counter Chinaâ€™s AI advancements while balancing U.S. influence in Europe.\n",
            "- **Innovation & Accessibility**:\n",
            "  - **Open vs. Closed Models**: Mistral AIâ€™s shift toward closed models (after initially open-sourcing some) may signal a trend toward proprietary AI, limiting transparency.\n",
            "  - **Cost & Accessibility**: If Microsoft integrates Mistral AIâ€™s models into Azure, it could lower barriers for European businesses to adopt AI.\n",
            "\n",
            "**<Ultimate Answer: The Mistral-Microsoft alliance could disrupt the AI market by providing a strong European alternative to U.S. models, accelerating innovation while intensifying regulatory and geopolitical tensions. Its success may depend on balancing independence with Microsoftâ€™s resources.>**\n",
            "\n",
            "---\n",
            "\n",
            "# **Comprehensive Analysis Report**\n",
            "\n",
            "```markdown\n",
            "# **Mistral AIâ€™s Strategic Leap: Performance, Partnerships, and Regulatory Challenges**\n",
            "\n",
            "## **1. Introduction**\n",
            "Mistral AI, a Paris-based AI startup founded in 2023 by ex-Google and Meta engineers, has rapidly emerged as a key player in the global AI race. Its latest announcementsâ€”**Mistral Large and Mistral Small**, alongside a **strategic partnership with Microsoft**â€”signal a bold push to compete with established U.S. and Chinese AI giants. This report examines:\n",
            "- The **performance and capabilities** of Mistral AIâ€™s new models.\n",
            "- The **implications of its Microsoft alliance** for Europeâ€™s AI ecosystem.\n",
            "- The **long-term competitive and regulatory impacts** on the global AI market.\n",
            "\n",
            "---\n",
            "\n",
            "## **2. Model Performance: A Lean but Powerful Contender**\n",
            "### **2.1 Benchmark Dominance**\n",
            "Mistral Largeâ€™s **81.2% score on the MMLU benchmark** places it ahead of:\n",
            "- Anthropicâ€™s Claude 2 (78.5%)\n",
            "- Googleâ€™s Gemini Pro (79.1%)\n",
            "- Metaâ€™s Llama 2 70B (68.9%)\n",
            "\n",
            "While it trails **GPT-4 (86.4%)** and **Gemini Ultra (90%)**, its performance is remarkable given:\n",
            "- **Undisclosed parameter counts**: Suggests **efficiency over brute-force scaling**, a potential advantage in cost and accessibility.\n",
            "- **Multilingual fluency**: Strong support for **French, German, Spanish, and Italian** gives it a **regional edge** over competitors with weaker European language capabilities.\n",
            "\n",
            "### **2.2 Functional & Enterprise Readiness**\n",
            "- **Function calling & JSON output**: Critical for **enterprise integration**, enabling automation and API-driven workflows.\n",
            "- **Closed-source shift**: After initially open-sourcing some models, Mistral AI is now **prioritizing proprietary solutions**, likely to monetize its technology more effectively.\n",
            "\n",
            "**Key Takeaway**: Mistral AI is positioning itself as a **high-performance, multilingual, and enterprise-ready** alternative to U.S. models, with a focus on **efficiency and regional relevance**.\n",
            "\n",
            "---\n",
            "\n",
            "## **3. The Microsoft Partnership: A Double-Edged Sword**\n",
            "### **3.1 Strategic Benefits**\n",
            "- **Computational Resources**: Microsoftâ€™s **Azure cloud infrastructure** provides Mistral AI with the **scalability** needed to train large models without massive upfront costs.\n",
            "- **Market Access**: Collaboration on **custom models for European governments** could accelerate adoption in public sector contracts.\n",
            "- **Financial Backing**: While Microsoftâ€™s investment is **small compared to its OpenAI stake**, it signals confidence in Mistral AIâ€™s potential.\n",
            "\n",
            "### **3.2 Regulatory & Political Backlash**\n",
            "The partnership has **divided European stakeholders** due to:\n",
            "1. **Market Concentration Concerns**\n",
            "   - Microsoft already dominates cloud computing (Azure) and AI (OpenAI). Critics argue this deal could **stifle competition** in Europeâ€™s AI ecosystem.\n",
            "   - **Alternative European AI firms** (e.g., Aleph Alpha, Hugging Face) may struggle to compete if Mistral AI becomes a **Microsoft-backed monopoly**.\n",
            "\n",
            "2. **Data Sovereignty & GDPR Risks**\n",
            "   - European governments may be **hesitant to use Microsoftâ€™s infrastructure** for sensitive data, fearing **U.S. jurisdiction** (e.g., CLOUD Act).\n",
            "   - **GDPR compliance** could become a hurdle if data processing occurs outside the EU.\n",
            "\n",
            "3. **Strategic Autonomy vs. U.S. Dependence**\n",
            "   - The EU has pushed for **\"digital sovereignty\"**, promoting homegrown tech. A Microsoft-Mistral alliance **undermines this goal** by tying a European champion to a U.S. giant.\n",
            "   - **Franceâ€™s AI strategy** (which includes Mistral AI as a national priority) may face **internal conflicts** if the startup becomes too reliant on Microsoft.\n",
            "\n",
            "**Key Takeaway**: While the partnership **accelerates Mistral AIâ€™s growth**, it risks **alienating regulators and policymakers** who prioritize European independence in AI.\n",
            "\n",
            "---\n",
            "\n",
            "## **4. Long-Term Implications for the Global AI Market**\n",
            "### **4.1 Competitive Landscape: A New Challenger Emerges**\n",
            "- **Pressure on U.S. Giants**: Mistral AIâ€™s **cost-efficient, high-performance models** could force OpenAI, Google, and Anthropic to **innovate faster** or risk losing market share in Europe.\n",
            "- **Chinaâ€™s AI Ambitions**: A strong European AI player could **counterbalance U.S. and Chinese dominance**, offering a **third pole** in global AI development.\n",
            "- **Startup Ecosystem**: If Mistral AI succeeds, it may **inspire more European AI startups**, fostering a **vibrant regional ecosystem**.\n",
            "\n",
            "### **4.2 Geopolitical & Regulatory Shifts**\n",
            "- **EU AI Act Compliance**: Mistral AIâ€™s models may be **better aligned with EU regulations**, giving it an advantage in **government and enterprise contracts**.\n",
            "- **Transatlantic Tech Rivalry**: The U.S. may view this partnership as a **strategic move to counter China**, while Europe seeks to **balance cooperation with independence**.\n",
            "- **Open vs. Closed AI**: Mistral AIâ€™s shift toward **proprietary models** could **reduce transparency** in AI development, raising concerns about **bias, accountability, and innovation**.\n",
            "\n",
            "### **4.3 Innovation & Accessibility**\n",
            "- **Democratizing AI**: If Microsoft integrates Mistral AIâ€™s models into **Azure**, it could **lower costs** for European businesses adopting AI.\n",
            "- **Customization for Enterprises**: The focus on **function calling and JSON output** suggests a **practical, business-oriented approach**, unlike some competitorsâ€™ more research-focused models.\n",
            "\n",
            "**Key Takeaway**: Mistral AIâ€™s rise could **reshape the AI market** by:\n",
            "âœ… **Providing a strong European alternative** to U.S. and Chinese models.\n",
            "âœ… **Accelerating innovation** through competition.\n",
            "âš ï¸ **Intensifying regulatory and geopolitical tensions** over AI sovereignty.\n",
            "\n",
            "---\n",
            "\n",
            "## **5. Conclusion: A High-Stakes Gamble with Global Impact**\n",
            "Mistral AIâ€™s **rapid progress** and **Microsoft partnership** represent a **major shift in the AI landscape**. While the startup has demonstrated **impressive technical capabilities**, its long-term success hinges on:\n",
            "1. **Balancing Microsoftâ€™s resources with European independence** to avoid regulatory backlash.\n",
            "2. **Maintaining performance leadership** while scaling efficiently.\n",
            "3. **Navigating geopolitical tensions** between the U.S., EU, and China.\n",
            "\n",
            "**Final Verdict**:\n",
            "- **For Mistral AI**: A **high-reward, high-risk strategy**â€”if executed well, it could become Europeâ€™s AI champion; if mismanaged, it risks becoming a **Microsoft subsidiary in disguise**.\n",
            "- **For the AI Market**: A **welcome disruption** that could **democratize access to high-performance AI** while **intensifying competition and regulatory scrutiny**.\n",
            "- **For Europe**: A **test of digital sovereignty**â€”can it foster a **homegrown AI leader** without relying on U.S. tech giants?\n",
            "\n",
            "The next 12-24 months will be **critical** in determining whether Mistral AI **redefines the AI race** or becomes another cautionary tale of **geopolitical and corporate tensions** in tech.\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### **Final Notes**\n",
            "- **Tone**: Professional yet engaging, balancing technical analysis with strategic insights.\n",
            "- **Structure**: Clear sections with **key takeaways** for quick reading.\n",
            "- **Depth**: Covers **performance, partnerships, and geopolitical implications** comprehensively.\n",
            "- **Future Outlook**: Ends with **forward-looking questions** to provoke discussion.\n",
            "\n",
            "Would you like any refinements or additional focus areas?\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt)\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
